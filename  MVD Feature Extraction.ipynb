{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db036706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from librosa.util import fix_length\n",
    "import scipy as sp\n",
    "import spafe\n",
    "from scipy.stats import kurtosis,skew,mode,gstd,describe,iqr,gmean,hmean,median_abs_deviation,variation,tstd,gstd,moment,entropy\n",
    "from spafe.features import pncc,gfcc,bfcc,mfcc,lfcc,lpc,ngcc,rplp,psrcc,msrcc\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54deb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "pth=glob(r\"C:\\Users\\Mohd Ashhad\\OneDrive\\Documents\\MVD Augmented\\*wav\") # insert path of folder which contains all recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb05d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pth[0]\n",
    "print(x[54:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731abdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fucntion that extracts features\n",
    "\n",
    "from spafe.features.gfcc import gfcc\n",
    "from spafe.features.mfcc import mfcc\n",
    "\n",
    "def features_extractor(file):\n",
    "    \n",
    "    #load the file (audio)\n",
    "    \n",
    "    sig, sr = librosa.load(file)\n",
    "    \n",
    "    # pad audio files to avoid any dimensional issue\n",
    "    \n",
    "    required_audio_size=3\n",
    "    audio = fix_length(sig, size=required_audio_size*sr) \n",
    "    \n",
    "    #Code for feature extraction\n",
    "\n",
    "    # local feature extraction (use only one feature as per requirement)\n",
    "    \n",
    "    S = gfcc(sig=sig, fs=sr, num_ceps=40,nfilts=128,nfft=2048,win_hop=0.0232,win_len=0.0464)\n",
    "#     S = mfcc(sig=sig, fs=sr, num_ceps=40,nfilts=128,nfft=2048,win_hop=0.0232,win_len=0.0464)\n",
    "#     S=librosa.feature.melspectrogram(sig, sr=sr, n_mels=128,n_fft=2048,hop_length=512,win_length=1024)\n",
    "\n",
    "    # Global feature extraction\n",
    "    \n",
    "    ft=sp.fft.fft(sig) # code for computing the spectrum using Fast Fourier Transform\n",
    "    magnitude=np.absolute(ft)\n",
    "    spec=magnitude[0:11025]\n",
    "    \n",
    "    k=kurtosis(spec)\n",
    "    s=skew(spec)\n",
    "    mean=np.mean(spec)\n",
    "    z=np.array(mode(spec)[0])\n",
    "    mode_var=float(z)\n",
    "    i=iqr(spec)\n",
    "    g=gmean(spec)\n",
    "    h=hmean(spec)\n",
    "    dev=median_abs_deviation(spec)\n",
    "    var=variation(spec)\n",
    "    variance=np.var(spec)\n",
    "    std=tstd(spec)\n",
    "    gstd_var=gstd(spec)\n",
    "    ent= entropy(spec)\n",
    "    \n",
    "    features=[mode_var,k,s,mean,i,g,h,dev,var,variance,std,gstd_var,ent]\n",
    "    features=normalize([features])\n",
    "    features=np.array(features)\n",
    "    features=np.reshape(features,(13,))\n",
    "    feat=[S,features] # save the matrix and vector in a list\n",
    "    \n",
    "    return feat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41962af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for building the dataframe and calling the feature extractor function to save the features within the dataframe\n",
    "\n",
    "def preproc_dataset(arr):\n",
    "    \n",
    "    features=[]\n",
    "    for v in arr:\n",
    "        f=features_extractor(v)\n",
    "        v = v.replace('.wav', '')\n",
    "        v=v[54 :] # replace the number (54) in this line with the number of characters to be removed from the beginning of the path of audio file \n",
    "        parts = v.split('_')\n",
    "        rec,name,series,vehicle= parts\n",
    "      \n",
    "        features.append({'file': v,\n",
    "                           'vehicle': vehicle,\n",
    "                           'series':series,\n",
    "                           'feature': f,\n",
    "                           })\n",
    "        \n",
    "    df_dataset = pd.DataFrame(mfcc, columns=('file','series', 'vehicle','feature'))      \n",
    "    return df_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e15017e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=preproc_dataset(pth)\n",
    "df_train=df_train.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78f3048",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['vehicle'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58494f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "z=df_train['feature']\n",
    "x=z.tolist()\n",
    "y=np.array(x,dtype=object)\n",
    "array=np.save('mvd_gfcc.npy',y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2b326f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df_train.drop(['feature'], axis=1)\n",
    "\n",
    "df_train.to_csv('mvd_gfcc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc548adb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
