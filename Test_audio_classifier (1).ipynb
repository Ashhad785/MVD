{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oC6oVAtzGJve",
        "outputId": "c54e5385-eb7a-4331-b6b3-0a6c708475a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting spafe==0.2.0\n",
            "  Downloading spafe-0.2.0-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.7/90.7 KB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.8/dist-packages (from spafe==0.2.0) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from spafe==0.2.0) (1.7.3)\n",
            "Installing collected packages: spafe\n",
            "Successfully installed spafe-0.2.0\n"
          ]
        }
      ],
      "source": [
        "# import all the dependencies\n",
        "import tensorflow as tf \n",
        "import pickle\n",
        "import numpy as np\n",
        "import librosa, librosa.display\n",
        "from librosa.util import fix_length\n",
        "import scipy as sp\n",
        "# !pip install spafe==0.2.0\n",
        "import spafe # make sure that the version of spafe installed is spafe==0.2.0\n",
        "from scipy.stats import kurtosis,skew,mode,gstd,describe,iqr,gmean,hmean,median_abs_deviation,variation,tstd,gstd,moment,entropy\n",
        "from spafe.features.gfcc import gfcc\n",
        "from sklearn.preprocessing import normalize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18d5wF27Iep_",
        "outputId": "7947b6e1-b214-410f-f43c-e46cb229d74b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keras model archive loading:\n",
            "File Name                                             Modified             Size\n",
            "variables.h5                                   2023-02-16 19:35:48       161256\n",
            "metadata.json                                  2023-02-16 19:35:48           64\n",
            "config.json                                    2023-02-16 19:35:48         5799\n",
            "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
            "...layers\n",
            "......concatenate\n",
            ".........vars\n",
            "......conv1d\n",
            ".........vars\n",
            "............0\n",
            "............1\n",
            "......conv1d_1\n",
            ".........vars\n",
            "............0\n",
            "............1\n",
            "......dense\n",
            ".........vars\n",
            "............0\n",
            "............1\n",
            "......dense_1\n",
            ".........vars\n",
            "............0\n",
            "............1\n",
            "......dense_2\n",
            ".........vars\n",
            "............0\n",
            "............1\n",
            "......dense_3\n",
            ".........vars\n",
            "............0\n",
            "............1\n",
            "......dense_4\n",
            ".........vars\n",
            "............0\n",
            "............1\n",
            "......flatten\n",
            ".........vars\n",
            "......input_layer\n",
            ".........vars\n",
            "......input_layer_1\n",
            ".........vars\n",
            "......max_pooling1d\n",
            ".........vars\n",
            "......max_pooling1d_1\n",
            ".........vars\n",
            "...metrics\n",
            "......mean\n",
            ".........vars\n",
            "............0\n",
            "............1\n",
            "......mean_metric_wrapper\n",
            ".........vars\n",
            "............0\n",
            "............1\n",
            "...vars\n",
            "1/1 [==============================] - 0s 343ms/step\n",
            "It is a motorbike\n",
            "confidence is  94.38365697860718 %\n"
          ]
        }
      ],
      "source": [
        "model = pickle.load(open('/content/drive/MyDrive/Eusipco Paper/model.pkl', 'rb')) # insert path of trained model here\n",
        "\n",
        "path= '/content/drive/MyDrive/Eusipco Paper/Omar-Audios-All/Motorcycle/Recording_1001_O_M.wav'  #Insert path of audio fetched from the app\n",
        "\n",
        "y, sr = librosa.load(path)\n",
        "required_audio_size = 3\n",
        "padded_signal = fix_length(y, size=required_audio_size*sr) \n",
        "\n",
        "\n",
        "Matrix  = gfcc(sig=padded_signal, fs=sr, num_ceps=40,nfilts=128,nfft=2048,win_hop=0.0232,win_len=0.0464)\n",
        "Matrix=np.reshape(Matrix,[1,128,40])\n",
        "\n",
        "ft=sp.fft.fft(y)\n",
        "magnitude=np.absolute(ft)\n",
        "hist=magnitude[0:11025]\n",
        "k=kurtosis(hist)\n",
        "s=skew(hist)\n",
        "mean=np.mean(hist)\n",
        "z=np.array(mode(hist)[0])\n",
        "mode_var=float(z)\n",
        "i=iqr(hist)\n",
        "g=gmean(hist)\n",
        "h=hmean(hist)\n",
        "dev=median_abs_deviation(hist)\n",
        "var=variation(hist)\n",
        "variance=np.var(hist)\n",
        "std=tstd(hist)\n",
        "gstd_var=gstd(hist)\n",
        "ent= entropy(hist)\n",
        "    \n",
        "\n",
        "features=[mode_var,k,s,mean,i,g,h,dev,var,variance,std,gstd_var,ent]\n",
        "vector=np.array(features)\n",
        "vector=normalize([vector])\n",
        "vector=np.reshape(vector,[1,13])\n",
        "\n",
        "predict1=model.predict([vector,Matrix])\n",
        "predict=(predict1 > 0.5).astype(\"int32\")\n",
        "confidence=predict1\n",
        "\n",
        "if predict[0][0]==1:\n",
        "  print(\"It is a car\")\n",
        "  print(\"confidence is \",confidence[0][0]*100 ,\"%\" )\n",
        "elif predict[0][1]==1:\n",
        "  print(\"It is a motorbike\")\n",
        "  print(\"confidence is \",confidence[0][1]*100,\"%\" )\n",
        "elif predict[0][3]==1:\n",
        "  print(\"It is a truck\")\n",
        "  print(\"confidence is \",confidence[0][3],\"%\" )\n",
        "else:\n",
        "  print(\"There is no vehicle in the audio\")\n",
        "\n",
        "# {'C': 0, 'M': 1, 'N': 2, 'T': 3}\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}