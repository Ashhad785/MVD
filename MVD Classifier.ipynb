{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Go1DaSewEuX2"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers, models,Sequential\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten,MaxPooling1D,Conv1D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.layers import Flatten, Input, concatenate\n",
        "import scipy as sp\n",
        "# !pip install spafe==0.2.0\n",
        "import spafe\n",
        "from spafe.features.gfcc import gfcc\n",
        "from scipy.stats import kurtosis,skew,mode,gstd,describe,iqr,gmean,hmean,median_abs_deviation,variation,tstd,gstd,moment,entropy\n",
        "import librosa, librosa.display\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import sklearn.metrics as skm\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/drive/MyDrive/Eusipco Paper/mvd_gfcc.csv')\n",
        "X_train=np.load('/content/drive/MyDrive/Eusipco Paper/mvd_gfcc.npy',allow_pickle=True)\n",
        "Y_train=np.array(df['vehicle'].tolist())"
      ],
      "metadata": {
        "id": "WoC9cmJCE4dH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['vehicle'].value_counts()"
      ],
      "metadata": {
        "id": "nzYnh-H03GpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_mlp(dim, regularizer=None):\n",
        "  \n",
        "    model = Sequential()\n",
        "    model.add(Dense(13, input_dim=dim, activation=\"relu\", kernel_regularizer=regularizer))\n",
        "    return model\n",
        "\n",
        "def create_cnn(width, height, filters=(64,32), regularizer=None):\n",
        "\n",
        "    inputShape = (height, width)\n",
        "    inputs = Input(shape=inputShape)\n",
        " \n",
        "    for (i, f) in enumerate(filters):\n",
        "\n",
        "        if i == 0:\n",
        "            x = inputs\n",
        "\n",
        "        x = Conv1D(f, (3), padding=\"same\")(x)\n",
        "        x = MaxPooling1D(pool_size=(2))(x)\n",
        "    \n",
        "    x = Flatten()(x)\n",
        "    x = Dense(13,activation=\"relu\", kernel_regularizer=regularizer)(x)\n",
        "    model = Model(inputs, x)\n",
        "    return model      "
      ],
      "metadata": {
        "id": "uXMDn_taFzqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strtfdKFold = StratifiedKFold(n_splits=5)\n",
        "kfold = strtfdKFold.split(X_train, Y_train)\n",
        "\n",
        "for k, (train, test) in enumerate(kfold):\n",
        "\n",
        "  X_tr=X_train[train,:]\n",
        "  Y_tr=Y_train[train]\n",
        "  X_te=X_train[test,:]\n",
        "  Y_te=Y_train[test]\n",
        "  \n",
        "  \n",
        "  labelencoder=LabelEncoder()\n",
        "  y_train=to_categorical(labelencoder.fit_transform(Y_tr))\n",
        "  labelencoder=LabelEncoder()\n",
        "  y_test=to_categorical(labelencoder.fit_transform(Y_te))\n",
        "  globalx_train=[]\n",
        "  localx_train=[]\n",
        "  globalx_test=[]\n",
        "  localx_test=[] \n",
        "\n",
        "  for i in range(len(X_tr)):\n",
        "    globalx_train.append(X_tr[i][1])\n",
        "    localx_train.append(X_tr[i][0])\n",
        "\n",
        "  for i in range(len(X_te)):\n",
        "    globalx_test.append(X_te[i][1])\n",
        "    localx_test.append(X_te[i][0])\n",
        "\n",
        "  globalx_train=np.array(globalx_train)\n",
        "  localx_train=np.array(localx_train)\n",
        "  globalx_test=np.array(globalx_test)\n",
        "  localx_test=np.array(localx_test)\n",
        "\n",
        "  mlp = create_mlp(13)\n",
        "  cnn = create_cnn(40,128)\n",
        "  \n",
        "  combinedInput = concatenate([mlp.output, cnn.output])\n",
        "\n",
        "  x=Dense(20, activation=\"relu\")(combinedInput)\n",
        "  x = Dense(100, activation=\"relu\")(x)\n",
        "  x = Dense(4, activation=\"softmax\")(x)\n",
        "\n",
        "  model1 = Model(inputs=[mlp.input, cnn.input], outputs=x)\n",
        "\n",
        "\n",
        "  opt = Adam(learning_rate=1e-3, decay=1e-3 / 200)\n",
        "  model1.compile(loss=\"categorical_crossentropy\", metrics=['acc'], optimizer=opt)\n",
        "  earlyStopping = EarlyStopping(monitor='val_loss', patience=7, verbose=0, mode='min')\n",
        "  mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
        "  reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4, verbose=1, min_delta=1e-4, mode='min')\n",
        "\n",
        "  model1_history = model1.fit( \n",
        "  [globalx_train, localx_train], \n",
        "  np.array(y_train), \n",
        "  validation_data=([globalx_test, localx_test],np.array(y_test)), \n",
        "  epochs=50,callbacks=[mcp_save, reduce_lr_loss,earlyStopping])\n",
        "  \n",
        "  print('\\n')\n",
        "  print(\"fold\",k)\n",
        "  print(\"Accuracy of the model on Training Data is - \" , model1.evaluate([globalx_train,localx_train], y_train)[1]*100 , \"%\")\n",
        "  print(\"Accuracy of the model on Testing Data is - \" , model1.evaluate([globalx_test, localx_test], y_test)[1]*100 , \"%\")\n",
        "  print('\\n')\n",
        "\n",
        "  y_predict=(model1.predict([globalx_test, localx_test]) > 0.5).astype(\"int32\")\n",
        "  y_true=y_test\n",
        "  cm= skm.multilabel_confusion_matrix(y_true, y_predict)\n",
        "  print(skm.classification_report(y_true,y_predict))\n",
        "  print('\\n')"
      ],
      "metadata": {
        "id": "kzZWvQsT8Z6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict(zip(labelencoder.classes_,range(len(labelencoder.classes_))))"
      ],
      "metadata": {
        "id": "OJ2rxwUMkYUs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}