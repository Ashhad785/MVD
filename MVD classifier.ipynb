{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Go1DaSewEuX2"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers, models,Sequential\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten,MaxPooling1D,Conv1D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.layers import Flatten, Input, concatenate\n",
        "import scipy as sp\n",
        "# !pip install spafe==0.2.0\n",
        "import spafe\n",
        "from spafe.features.gfcc import gfcc\n",
        "from scipy.stats import kurtosis,skew,mode,gstd,describe,iqr,gmean,hmean,median_abs_deviation,variation,tstd,gstd,moment,entropy\n",
        "import librosa, librosa.display\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import sklearn.metrics as skm\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/drive/MyDrive/Eusipco Paper/mvd_gfcc.csv')\n",
        "X_train=np.load('/content/drive/MyDrive/Eusipco Paper/mvd_gfcc.npy',allow_pickle=True)\n",
        "Y_train=np.array(df['vehicle'].tolist())"
      ],
      "metadata": {
        "id": "WoC9cmJCE4dH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['vehicle'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzYnh-H03GpY",
        "outputId": "af6f12cc-2327-4527-b0e0-f49b06f1f0f2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "M    4488\n",
              "T    4308\n",
              "N    4100\n",
              "C    4020\n",
              "Name: vehicle, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_mlp(dim, regularizer=None):\n",
        "  \n",
        "    model = Sequential()\n",
        "    model.add(Dense(13, input_dim=dim, activation=\"relu\", kernel_regularizer=regularizer))\n",
        "    return model\n",
        "\n",
        "def create_cnn(width, height, filters=(64,32), regularizer=None):\n",
        "\n",
        "    inputShape = (height, width)\n",
        "    inputs = Input(shape=inputShape)\n",
        " \n",
        "    for (i, f) in enumerate(filters):\n",
        "\n",
        "        if i == 0:\n",
        "            x = inputs\n",
        "\n",
        "        x = Conv1D(f, (3), padding=\"same\")(x)\n",
        "        x = MaxPooling1D(pool_size=(2))(x)\n",
        "    \n",
        "    x = Flatten()(x)\n",
        "    x = Dense(13,activation=\"relu\", kernel_regularizer=regularizer)(x)\n",
        "    model = Model(inputs, x)\n",
        "    return model      "
      ],
      "metadata": {
        "id": "uXMDn_taFzqZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strtfdKFold = StratifiedKFold(n_splits=5)\n",
        "kfold = strtfdKFold.split(X_train, Y_train)\n",
        "\n",
        "for k, (train, test) in enumerate(kfold):\n",
        "\n",
        "  X_tr=X_train[train,:]\n",
        "  Y_tr=Y_train[train]\n",
        "  X_te=X_train[test,:]\n",
        "  Y_te=Y_train[test]\n",
        "  \n",
        "  \n",
        "  labelencoder=LabelEncoder()\n",
        "  y_train=to_categorical(labelencoder.fit_transform(Y_tr))\n",
        "  labelencoder=LabelEncoder()\n",
        "  y_test=to_categorical(labelencoder.fit_transform(Y_te))\n",
        "  globalx_train=[]\n",
        "  localx_train=[]\n",
        "  globalx_test=[]\n",
        "  localx_test=[] \n",
        "\n",
        "  for i in range(len(X_tr)):\n",
        "    globalx_train.append(X_tr[i][1])\n",
        "    localx_train.append(X_tr[i][0])\n",
        "\n",
        "  for i in range(len(X_te)):\n",
        "    globalx_test.append(X_te[i][1])\n",
        "    localx_test.append(X_te[i][0])\n",
        "\n",
        "  globalx_train=np.array(globalx_train)\n",
        "  localx_train=np.array(localx_train)\n",
        "  globalx_test=np.array(globalx_test)\n",
        "  localx_test=np.array(localx_test)\n",
        "\n",
        "  mlp = create_mlp(13)\n",
        "  cnn = create_cnn(40,128)\n",
        "  \n",
        "  combinedInput = concatenate([mlp.output, cnn.output])\n",
        "\n",
        "  x=Dense(20, activation=\"relu\")(combinedInput)\n",
        "  x = Dense(100, activation=\"relu\")(x)\n",
        "  x = Dense(4, activation=\"softmax\")(x)\n",
        "\n",
        "  model1 = Model(inputs=[mlp.input, cnn.input], outputs=x)\n",
        "\n",
        "\n",
        "  opt = Adam(learning_rate=1e-3, decay=1e-3 / 200)\n",
        "  model1.compile(loss=\"categorical_crossentropy\", metrics=['acc'], optimizer=opt)\n",
        "  earlyStopping = EarlyStopping(monitor='val_loss', patience=7, verbose=0, mode='min')\n",
        "  mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
        "  reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4, verbose=1, min_delta=1e-4, mode='min')\n",
        "\n",
        "  model1_history = model1.fit( \n",
        "  [globalx_train, localx_train], \n",
        "  np.array(y_train), \n",
        "  validation_data=([globalx_test, localx_test],np.array(y_test)), \n",
        "  epochs=50,callbacks=[mcp_save, reduce_lr_loss,earlyStopping])\n",
        "  \n",
        "  print('\\n')\n",
        "  print(\"fold\",k)\n",
        "  print(\"Accuracy of the model on Training Data is - \" , model1.evaluate([globalx_train,localx_train], y_train)[1]*100 , \"%\")\n",
        "  print(\"Accuracy of the model on Testing Data is - \" , model1.evaluate([globalx_test, localx_test], y_test)[1]*100 , \"%\")\n",
        "  print('\\n')\n",
        "\n",
        "  y_predict=(model1.predict([globalx_test, localx_test]) > 0.5).astype(\"int32\")\n",
        "  y_true=y_test\n",
        "  cm= skm.multilabel_confusion_matrix(y_true, y_predict)\n",
        "  print(skm.classification_report(y_true,y_predict))\n",
        "  print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzZWvQsT8Z6t",
        "outputId": "0f7577c4-e323-4798-b0cf-9ede32294ed9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "423/423 [==============================] - 10s 21ms/step - loss: 0.5099 - acc: 0.8018 - val_loss: 0.3824 - val_acc: 0.8549 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "423/423 [==============================] - 10s 24ms/step - loss: 0.3141 - acc: 0.8838 - val_loss: 0.3459 - val_acc: 0.8644 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "423/423 [==============================] - 10s 23ms/step - loss: 0.2833 - acc: 0.8968 - val_loss: 0.2994 - val_acc: 0.8883 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "423/423 [==============================] - 8s 18ms/step - loss: 0.2549 - acc: 0.9049 - val_loss: 0.2814 - val_acc: 0.8921 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "423/423 [==============================] - 10s 23ms/step - loss: 0.2314 - acc: 0.9143 - val_loss: 0.2681 - val_acc: 0.9007 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "423/423 [==============================] - 8s 20ms/step - loss: 0.2044 - acc: 0.9257 - val_loss: 0.2323 - val_acc: 0.9116 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "423/423 [==============================] - 9s 20ms/step - loss: 0.1796 - acc: 0.9371 - val_loss: 0.2512 - val_acc: 0.9099 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "423/423 [==============================] - 10s 23ms/step - loss: 0.1615 - acc: 0.9432 - val_loss: 0.2533 - val_acc: 0.9078 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "423/423 [==============================] - 8s 20ms/step - loss: 0.1424 - acc: 0.9500 - val_loss: 0.2025 - val_acc: 0.9303 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "423/423 [==============================] - 10s 23ms/step - loss: 0.1277 - acc: 0.9541 - val_loss: 0.2133 - val_acc: 0.9297 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "423/423 [==============================] - 8s 20ms/step - loss: 0.1125 - acc: 0.9611 - val_loss: 0.2001 - val_acc: 0.9397 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "423/423 [==============================] - 9s 21ms/step - loss: 0.1068 - acc: 0.9623 - val_loss: 0.1986 - val_acc: 0.9338 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "423/423 [==============================] - 10s 23ms/step - loss: 0.0901 - acc: 0.9693 - val_loss: 0.1802 - val_acc: 0.9453 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "423/423 [==============================] - 8s 18ms/step - loss: 0.0815 - acc: 0.9728 - val_loss: 0.2444 - val_acc: 0.9291 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "423/423 [==============================] - 10s 23ms/step - loss: 0.0727 - acc: 0.9749 - val_loss: 0.1659 - val_acc: 0.9527 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "423/423 [==============================] - 8s 20ms/step - loss: 0.0622 - acc: 0.9792 - val_loss: 0.2064 - val_acc: 0.9409 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "423/423 [==============================] - 9s 21ms/step - loss: 0.0491 - acc: 0.9829 - val_loss: 0.1814 - val_acc: 0.9527 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "423/423 [==============================] - 9s 22ms/step - loss: 0.0547 - acc: 0.9816 - val_loss: 0.2278 - val_acc: 0.9489 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "422/423 [============================>.] - ETA: 0s - loss: 0.0554 - acc: 0.9809\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "423/423 [==============================] - 8s 18ms/step - loss: 0.0556 - acc: 0.9808 - val_loss: 0.1776 - val_acc: 0.9536 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "423/423 [==============================] - 10s 23ms/step - loss: 0.0214 - acc: 0.9939 - val_loss: 0.1585 - val_acc: 0.9589 - lr: 1.0000e-04\n",
            "Epoch 21/50\n",
            "423/423 [==============================] - 8s 18ms/step - loss: 0.0156 - acc: 0.9958 - val_loss: 0.1601 - val_acc: 0.9601 - lr: 1.0000e-04\n",
            "Epoch 22/50\n",
            "423/423 [==============================] - 10s 23ms/step - loss: 0.0137 - acc: 0.9964 - val_loss: 0.1629 - val_acc: 0.9592 - lr: 1.0000e-04\n",
            "Epoch 23/50\n",
            "423/423 [==============================] - 9s 22ms/step - loss: 0.0122 - acc: 0.9971 - val_loss: 0.1681 - val_acc: 0.9598 - lr: 1.0000e-04\n",
            "Epoch 24/50\n",
            "423/423 [==============================] - ETA: 0s - loss: 0.0110 - acc: 0.9975\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "423/423 [==============================] - 13s 31ms/step - loss: 0.0110 - acc: 0.9975 - val_loss: 0.1704 - val_acc: 0.9604 - lr: 1.0000e-04\n",
            "Epoch 25/50\n",
            "423/423 [==============================] - 10s 23ms/step - loss: 0.0096 - acc: 0.9978 - val_loss: 0.1702 - val_acc: 0.9604 - lr: 1.0000e-05\n",
            "Epoch 26/50\n",
            "423/423 [==============================] - 8s 18ms/step - loss: 0.0094 - acc: 0.9980 - val_loss: 0.1706 - val_acc: 0.9601 - lr: 1.0000e-05\n",
            "Epoch 27/50\n",
            "423/423 [==============================] - 10s 23ms/step - loss: 0.0093 - acc: 0.9980 - val_loss: 0.1714 - val_acc: 0.9601 - lr: 1.0000e-05\n",
            "\n",
            "\n",
            "fold 0\n",
            "423/423 [==============================] - 3s 7ms/step - loss: 0.0091 - acc: 0.9979\n",
            "Accuracy of the model on Training Data is -  99.79308247566223 %\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 0.1714 - acc: 0.9601\n",
            "Accuracy of the model on Testing Data is -  96.0106372833252 %\n",
            "\n",
            "\n",
            "106/106 [==============================] - 1s 10ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.93      0.94       804\n",
            "           1       0.94      0.95      0.95       898\n",
            "           2       0.98      1.00      0.99       820\n",
            "           3       0.97      0.96      0.97       862\n",
            "\n",
            "   micro avg       0.96      0.96      0.96      3384\n",
            "   macro avg       0.96      0.96      0.96      3384\n",
            "weighted avg       0.96      0.96      0.96      3384\n",
            " samples avg       0.96      0.96      0.96      3384\n",
            "\n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "423/423 [==============================] - 11s 22ms/step - loss: 0.5077 - acc: 0.8001 - val_loss: 0.3282 - val_acc: 0.8779 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "423/423 [==============================] - 10s 23ms/step - loss: 0.3244 - acc: 0.8801 - val_loss: 0.2852 - val_acc: 0.8897 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "423/423 [==============================] - 9s 22ms/step - loss: 0.2805 - acc: 0.8967 - val_loss: 0.2812 - val_acc: 0.8912 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "423/423 [==============================] - 8s 19ms/step - loss: 0.2532 - acc: 0.9080 - val_loss: 0.2714 - val_acc: 0.9022 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "423/423 [==============================] - 10s 23ms/step - loss: 0.2290 - acc: 0.9169 - val_loss: 0.2314 - val_acc: 0.9143 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "423/423 [==============================] - 8s 18ms/step - loss: 0.1974 - acc: 0.9265 - val_loss: 0.2071 - val_acc: 0.9264 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "423/423 [==============================] - 10s 22ms/step - loss: 0.1679 - acc: 0.9402 - val_loss: 0.1764 - val_acc: 0.9338 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "423/423 [==============================] - 8s 19ms/step - loss: 0.1523 - acc: 0.9467 - val_loss: 0.1766 - val_acc: 0.9353 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "423/423 [==============================] - 9s 21ms/step - loss: 0.1416 - acc: 0.9500 - val_loss: 0.1850 - val_acc: 0.9356 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "423/423 [==============================] - 10s 23ms/step - loss: 0.1162 - acc: 0.9584 - val_loss: 0.1515 - val_acc: 0.9474 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "423/423 [==============================] - 8s 18ms/step - loss: 0.1110 - acc: 0.9612 - val_loss: 0.1657 - val_acc: 0.9459 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "423/423 [==============================] - 10s 23ms/step - loss: 0.0805 - acc: 0.9721 - val_loss: 0.1697 - val_acc: 0.9486 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "423/423 [==============================] - 8s 18ms/step - loss: 0.0948 - acc: 0.9685 - val_loss: 0.1378 - val_acc: 0.9533 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "423/423 [==============================] - 9s 22ms/step - loss: 0.0594 - acc: 0.9798 - val_loss: 0.1401 - val_acc: 0.9548 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "423/423 [==============================] - 9s 20ms/step - loss: 0.0554 - acc: 0.9813 - val_loss: 0.1058 - val_acc: 0.9654 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "423/423 [==============================] - 9s 20ms/step - loss: 0.0572 - acc: 0.9811 - val_loss: 0.1849 - val_acc: 0.9506 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "423/423 [==============================] - 10s 23ms/step - loss: 0.0563 - acc: 0.9803 - val_loss: 0.1687 - val_acc: 0.9506 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "423/423 [==============================] - 8s 18ms/step - loss: 0.0455 - acc: 0.9842 - val_loss: 0.1510 - val_acc: 0.9595 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "422/423 [============================>.] - ETA: 0s - loss: 0.0389 - acc: 0.9877\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "423/423 [==============================] - 9s 22ms/step - loss: 0.0388 - acc: 0.9877 - val_loss: 0.1701 - val_acc: 0.9509 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "423/423 [==============================] - 8s 18ms/step - loss: 0.0209 - acc: 0.9940 - val_loss: 0.1149 - val_acc: 0.9687 - lr: 1.0000e-04\n",
            "Epoch 21/50\n",
            "423/423 [==============================] - 9s 22ms/step - loss: 0.0134 - acc: 0.9965 - val_loss: 0.1134 - val_acc: 0.9701 - lr: 1.0000e-04\n",
            "Epoch 22/50\n",
            "423/423 [==============================] - 9s 20ms/step - loss: 0.0109 - acc: 0.9975 - val_loss: 0.1129 - val_acc: 0.9710 - lr: 1.0000e-04\n",
            "\n",
            "\n",
            "fold 1\n",
            "423/423 [==============================] - 3s 8ms/step - loss: 0.0093 - acc: 0.9979\n",
            "Accuracy of the model on Training Data is -  99.79310035705566 %\n",
            "106/106 [==============================] - 1s 6ms/step - loss: 0.1129 - acc: 0.9710\n",
            "Accuracy of the model on Testing Data is -  97.10316061973572 %\n",
            "\n",
            "\n",
            "106/106 [==============================] - 1s 6ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.96      0.96       804\n",
            "           1       0.95      0.97      0.96       897\n",
            "           2       1.00      0.99      0.99       820\n",
            "           3       0.98      0.96      0.97       862\n",
            "\n",
            "   micro avg       0.97      0.97      0.97      3383\n",
            "   macro avg       0.97      0.97      0.97      3383\n",
            "weighted avg       0.97      0.97      0.97      3383\n",
            " samples avg       0.97      0.97      0.97      3383\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "423/423 [==============================] - 11s 23ms/step - loss: 0.4770 - acc: 0.8172 - val_loss: 0.3392 - val_acc: 0.8723 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "423/423 [==============================] - 8s 19ms/step - loss: 0.3063 - acc: 0.8869 - val_loss: 0.3175 - val_acc: 0.8794 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "423/423 [==============================] - 9s 20ms/step - loss: 0.2840 - acc: 0.8934 - val_loss: 0.2671 - val_acc: 0.9042 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "423/423 [==============================] - 10s 23ms/step - loss: 0.2469 - acc: 0.9077 - val_loss: 0.2627 - val_acc: 0.9078 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "423/423 [==============================] - 10s 23ms/step - loss: 0.2251 - acc: 0.9181 - val_loss: 0.2545 - val_acc: 0.9033 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "423/423 [==============================] - 10s 23ms/step - loss: 0.2000 - acc: 0.9277 - val_loss: 0.1978 - val_acc: 0.9282 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "423/423 [==============================] - 9s 20ms/step - loss: 0.1755 - acc: 0.9404 - val_loss: 0.1904 - val_acc: 0.9314 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "423/423 [==============================] - 10s 23ms/step - loss: 0.1535 - acc: 0.9447 - val_loss: 0.2128 - val_acc: 0.9237 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "423/423 [==============================] - 9s 22ms/step - loss: 0.1286 - acc: 0.9546 - val_loss: 0.1613 - val_acc: 0.9450 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "423/423 [==============================] - 8s 19ms/step - loss: 0.1236 - acc: 0.9564 - val_loss: 0.1611 - val_acc: 0.9456 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "423/423 [==============================] - 11s 26ms/step - loss: 0.0960 - acc: 0.9667 - val_loss: 0.1627 - val_acc: 0.9465 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "423/423 [==============================] - 8s 20ms/step - loss: 0.0871 - acc: 0.9685 - val_loss: 0.1638 - val_acc: 0.9474 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "423/423 [==============================] - 9s 22ms/step - loss: 0.0716 - acc: 0.9744 - val_loss: 0.1362 - val_acc: 0.9583 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "423/423 [==============================] - 10s 24ms/step - loss: 0.0632 - acc: 0.9777 - val_loss: 0.1588 - val_acc: 0.9539 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "423/423 [==============================] - 8s 18ms/step - loss: 0.0571 - acc: 0.9804 - val_loss: 0.1743 - val_acc: 0.9497 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "423/423 [==============================] - 10s 23ms/step - loss: 0.0570 - acc: 0.9808 - val_loss: 0.1618 - val_acc: 0.9545 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "421/423 [============================>.] - ETA: 0s - loss: 0.0401 - acc: 0.9852\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "423/423 [==============================] - 8s 18ms/step - loss: 0.0401 - acc: 0.9851 - val_loss: 0.1540 - val_acc: 0.9598 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "423/423 [==============================] - 10s 23ms/step - loss: 0.0164 - acc: 0.9960 - val_loss: 0.1346 - val_acc: 0.9660 - lr: 1.0000e-04\n",
            "Epoch 19/50\n",
            "423/423 [==============================] - 9s 21ms/step - loss: 0.0109 - acc: 0.9976 - val_loss: 0.1350 - val_acc: 0.9669 - lr: 1.0000e-04\n",
            "Epoch 20/50\n",
            "423/423 [==============================] - 9s 20ms/step - loss: 0.0092 - acc: 0.9981 - val_loss: 0.1362 - val_acc: 0.9684 - lr: 1.0000e-04\n",
            "Epoch 21/50\n",
            "423/423 [==============================] - 10s 23ms/step - loss: 0.0079 - acc: 0.9987 - val_loss: 0.1391 - val_acc: 0.9681 - lr: 1.0000e-04\n",
            "Epoch 22/50\n",
            "420/423 [============================>.] - ETA: 0s - loss: 0.0070 - acc: 0.9989\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "423/423 [==============================] - 8s 18ms/step - loss: 0.0069 - acc: 0.9989 - val_loss: 0.1399 - val_acc: 0.9675 - lr: 1.0000e-04\n",
            "Epoch 23/50\n",
            "423/423 [==============================] - 10s 23ms/step - loss: 0.0059 - acc: 0.9992 - val_loss: 0.1404 - val_acc: 0.9684 - lr: 1.0000e-05\n",
            "Epoch 24/50\n",
            "423/423 [==============================] - 8s 20ms/step - loss: 0.0057 - acc: 0.9992 - val_loss: 0.1409 - val_acc: 0.9684 - lr: 1.0000e-05\n",
            "Epoch 25/50\n",
            "423/423 [==============================] - 9s 21ms/step - loss: 0.0057 - acc: 0.9993 - val_loss: 0.1413 - val_acc: 0.9684 - lr: 1.0000e-05\n",
            "\n",
            "\n",
            "fold 2\n",
            "423/423 [==============================] - 3s 7ms/step - loss: 0.0055 - acc: 0.9993\n",
            "Accuracy of the model on Training Data is -  99.93349313735962 %\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 0.1413 - acc: 0.9684\n",
            "Accuracy of the model on Testing Data is -  96.83712720870972 %\n",
            "\n",
            "\n",
            "106/106 [==============================] - 1s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.95      0.95       804\n",
            "           1       0.96      0.96      0.96       897\n",
            "           2       0.99      0.99      0.99       820\n",
            "           3       0.97      0.97      0.97       862\n",
            "\n",
            "   micro avg       0.97      0.97      0.97      3383\n",
            "   macro avg       0.97      0.97      0.97      3383\n",
            "weighted avg       0.97      0.97      0.97      3383\n",
            " samples avg       0.97      0.97      0.97      3383\n",
            "\n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "423/423 [==============================] - 12s 24ms/step - loss: 0.4828 - acc: 0.8153 - val_loss: 0.3256 - val_acc: 0.8815 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "423/423 [==============================] - 9s 22ms/step - loss: 0.3141 - acc: 0.8821 - val_loss: 0.3144 - val_acc: 0.8812 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "423/423 [==============================] - 8s 18ms/step - loss: 0.2744 - acc: 0.9002 - val_loss: 0.2574 - val_acc: 0.9072 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "423/423 [==============================] - 9s 22ms/step - loss: 0.2397 - acc: 0.9132 - val_loss: 0.2483 - val_acc: 0.9110 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "423/423 [==============================] - 8s 20ms/step - loss: 0.2126 - acc: 0.9209 - val_loss: 0.2390 - val_acc: 0.9149 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "423/423 [==============================] - 8s 20ms/step - loss: 0.1868 - acc: 0.9325 - val_loss: 0.2035 - val_acc: 0.9273 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "423/423 [==============================] - 9s 22ms/step - loss: 0.1611 - acc: 0.9401 - val_loss: 0.1915 - val_acc: 0.9335 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "423/423 [==============================] - 8s 18ms/step - loss: 0.1401 - acc: 0.9503 - val_loss: 0.1624 - val_acc: 0.9412 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "423/423 [==============================] - 10s 24ms/step - loss: 0.1301 - acc: 0.9526 - val_loss: 0.2199 - val_acc: 0.9237 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "423/423 [==============================] - 13s 30ms/step - loss: 0.1095 - acc: 0.9625 - val_loss: 0.1847 - val_acc: 0.9400 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "423/423 [==============================] - 8s 18ms/step - loss: 0.0915 - acc: 0.9691 - val_loss: 0.1526 - val_acc: 0.9500 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "423/423 [==============================] - 9s 22ms/step - loss: 0.0812 - acc: 0.9713 - val_loss: 0.1505 - val_acc: 0.9509 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "423/423 [==============================] - 7s 18ms/step - loss: 0.0736 - acc: 0.9741 - val_loss: 0.1842 - val_acc: 0.9391 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "423/423 [==============================] - 10s 23ms/step - loss: 0.0755 - acc: 0.9751 - val_loss: 0.1387 - val_acc: 0.9589 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "423/423 [==============================] - 8s 19ms/step - loss: 0.0614 - acc: 0.9777 - val_loss: 0.1683 - val_acc: 0.9557 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "423/423 [==============================] - 9s 21ms/step - loss: 0.0599 - acc: 0.9781 - val_loss: 0.1373 - val_acc: 0.9619 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "423/423 [==============================] - 10s 23ms/step - loss: 0.0357 - acc: 0.9891 - val_loss: 0.1386 - val_acc: 0.9633 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "423/423 [==============================] - 8s 18ms/step - loss: 0.0505 - acc: 0.9837 - val_loss: 0.2564 - val_acc: 0.9338 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "423/423 [==============================] - 9s 22ms/step - loss: 0.0479 - acc: 0.9832 - val_loss: 0.1334 - val_acc: 0.9654 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "423/423 [==============================] - 7s 18ms/step - loss: 0.0298 - acc: 0.9890 - val_loss: 0.1979 - val_acc: 0.9527 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "423/423 [==============================] - 9s 22ms/step - loss: 0.0376 - acc: 0.9868 - val_loss: 0.1758 - val_acc: 0.9551 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "423/423 [==============================] - 8s 19ms/step - loss: 0.0221 - acc: 0.9930 - val_loss: 0.2077 - val_acc: 0.9554 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "421/423 [============================>.] - ETA: 0s - loss: 0.0447 - acc: 0.9857\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "423/423 [==============================] - 9s 21ms/step - loss: 0.0445 - acc: 0.9857 - val_loss: 0.1876 - val_acc: 0.9542 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "423/423 [==============================] - 9s 21ms/step - loss: 0.0163 - acc: 0.9950 - val_loss: 0.1538 - val_acc: 0.9663 - lr: 1.0000e-04\n",
            "Epoch 25/50\n",
            "423/423 [==============================] - 8s 19ms/step - loss: 0.0083 - acc: 0.9978 - val_loss: 0.1536 - val_acc: 0.9666 - lr: 1.0000e-04\n",
            "Epoch 26/50\n",
            "423/423 [==============================] - 10s 22ms/step - loss: 0.0067 - acc: 0.9986 - val_loss: 0.1530 - val_acc: 0.9684 - lr: 1.0000e-04\n",
            "\n",
            "\n",
            "fold 3\n",
            "423/423 [==============================] - 3s 7ms/step - loss: 0.0057 - acc: 0.9989\n",
            "Accuracy of the model on Training Data is -  99.88915920257568 %\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 0.1530 - acc: 0.9684\n",
            "Accuracy of the model on Testing Data is -  96.83712720870972 %\n",
            "\n",
            "\n",
            "106/106 [==============================] - 1s 7ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.97      0.95       804\n",
            "           1       0.96      0.96      0.96       898\n",
            "           2       0.99      0.99      0.99       820\n",
            "           3       0.98      0.96      0.97       861\n",
            "\n",
            "   micro avg       0.97      0.97      0.97      3383\n",
            "   macro avg       0.97      0.97      0.97      3383\n",
            "weighted avg       0.97      0.97      0.97      3383\n",
            " samples avg       0.97      0.97      0.97      3383\n",
            "\n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "423/423 [==============================] - 10s 22ms/step - loss: 0.5820 - acc: 0.7537 - val_loss: 0.3276 - val_acc: 0.8868 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "423/423 [==============================] - 8s 20ms/step - loss: 0.3285 - acc: 0.8815 - val_loss: 0.3071 - val_acc: 0.8859 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "423/423 [==============================] - 10s 23ms/step - loss: 0.2861 - acc: 0.8980 - val_loss: 0.2623 - val_acc: 0.9033 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "423/423 [==============================] - 8s 18ms/step - loss: 0.2528 - acc: 0.9083 - val_loss: 0.2398 - val_acc: 0.9155 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "423/423 [==============================] - 10s 24ms/step - loss: 0.2317 - acc: 0.9167 - val_loss: 0.2174 - val_acc: 0.9228 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "423/423 [==============================] - 9s 20ms/step - loss: 0.2067 - acc: 0.9263 - val_loss: 0.2104 - val_acc: 0.9261 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "423/423 [==============================] - 9s 21ms/step - loss: 0.1811 - acc: 0.9364 - val_loss: 0.2588 - val_acc: 0.9113 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "423/423 [==============================] - 10s 23ms/step - loss: 0.1550 - acc: 0.9455 - val_loss: 0.1781 - val_acc: 0.9344 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "423/423 [==============================] - 8s 18ms/step - loss: 0.1421 - acc: 0.9500 - val_loss: 0.1690 - val_acc: 0.9430 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "423/423 [==============================] - 9s 22ms/step - loss: 0.1190 - acc: 0.9604 - val_loss: 0.1780 - val_acc: 0.9418 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "423/423 [==============================] - 7s 18ms/step - loss: 0.1074 - acc: 0.9632 - val_loss: 0.1553 - val_acc: 0.9483 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "423/423 [==============================] - 9s 22ms/step - loss: 0.0929 - acc: 0.9687 - val_loss: 0.1504 - val_acc: 0.9521 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "423/423 [==============================] - 8s 20ms/step - loss: 0.0786 - acc: 0.9737 - val_loss: 0.1333 - val_acc: 0.9545 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "423/423 [==============================] - 9s 20ms/step - loss: 0.0693 - acc: 0.9778 - val_loss: 0.1650 - val_acc: 0.9447 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "423/423 [==============================] - 9s 22ms/step - loss: 0.0711 - acc: 0.9758 - val_loss: 0.2181 - val_acc: 0.9305 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "423/423 [==============================] - 7s 18ms/step - loss: 0.0612 - acc: 0.9778 - val_loss: 0.1820 - val_acc: 0.9441 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "423/423 [==============================] - 9s 22ms/step - loss: 0.0522 - acc: 0.9829 - val_loss: 0.1211 - val_acc: 0.9628 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "423/423 [==============================] - 7s 18ms/step - loss: 0.0425 - acc: 0.9863 - val_loss: 0.1356 - val_acc: 0.9616 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "423/423 [==============================] - 9s 22ms/step - loss: 0.0495 - acc: 0.9837 - val_loss: 0.1561 - val_acc: 0.9557 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "423/423 [==============================] - 8s 19ms/step - loss: 0.0355 - acc: 0.9886 - val_loss: 0.1619 - val_acc: 0.9536 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "421/423 [============================>.] - ETA: 0s - loss: 0.0349 - acc: 0.9883\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "423/423 [==============================] - 9s 21ms/step - loss: 0.0350 - acc: 0.9883 - val_loss: 0.1517 - val_acc: 0.9580 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "423/423 [==============================] - 9s 21ms/step - loss: 0.0158 - acc: 0.9955 - val_loss: 0.1391 - val_acc: 0.9639 - lr: 1.0000e-04\n",
            "Epoch 23/50\n",
            "423/423 [==============================] - 8s 18ms/step - loss: 0.0113 - acc: 0.9970 - val_loss: 0.1433 - val_acc: 0.9645 - lr: 1.0000e-04\n",
            "Epoch 24/50\n",
            "423/423 [==============================] - 12s 27ms/step - loss: 0.0099 - acc: 0.9978 - val_loss: 0.1441 - val_acc: 0.9654 - lr: 1.0000e-04\n",
            "\n",
            "\n",
            "fold 4\n",
            "423/423 [==============================] - 3s 6ms/step - loss: 0.0087 - acc: 0.9979\n",
            "Accuracy of the model on Training Data is -  99.78570938110352 %\n",
            "106/106 [==============================] - 1s 6ms/step - loss: 0.1441 - acc: 0.9654\n",
            "Accuracy of the model on Testing Data is -  96.54152989387512 %\n",
            "\n",
            "\n",
            "106/106 [==============================] - 1s 6ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.96      0.95       804\n",
            "           1       0.97      0.95      0.96       898\n",
            "           2       0.99      0.99      0.99       820\n",
            "           3       0.97      0.97      0.97       861\n",
            "\n",
            "   micro avg       0.97      0.97      0.97      3383\n",
            "   macro avg       0.97      0.97      0.97      3383\n",
            "weighted avg       0.97      0.97      0.97      3383\n",
            " samples avg       0.97      0.97      0.97      3383\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict(zip(labelencoder.classes_,range(len(labelencoder.classes_))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJ2rxwUMkYUs",
        "outputId": "794676cd-0632-4e56-fa5c-bb19b47f7135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 0, 'M': 1, 'N': 2, 'T': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}